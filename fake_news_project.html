<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Fake News Project</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/journal.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>




<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 61px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 66px;
  margin-top: -66px;
}

.section h2 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h3 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h4 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h5 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h6 {
  padding-top: 66px;
  margin-top: -66px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Portfolio</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="about_me.html">About Me</a>
</li>
<li>
  <a href="contact.html">Contact</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Fake News Project</h1>

</div>


<p>Our goal for this project was to look at how different political parties viewed fakes news. Our data set was from the PEW Research center and it contained question such as “How well do you think you can determine a fake news story”. These type of questions are the PEW questions which are:</p>
<p>PEW1: How often do you come across news stories about politics that you think are not totally accurate?<br />
PEW2: And how often do you come across news stories about politics that you think completely made up?<br />
PEW3: Have you shared a news story you later found out was made up?<br />
PEW4: Have you shared a news story you thought at the time was made up?<br />
PEW5a: How much responsibility do members of the public have in trying to prevent made up stories from gaining public attention? PEW5b: How much responsibility do government and elected officials have in trying to prevent made up stories from gaining public attention? PEW5c: How much responsibility do social media websites have in trying to prevent made up stories from gaining public attention? PEW6: How confident are you in your ability to recognize news that is made up?<br />
PEW7: How much do you think these kind of stories leave Americans confused about the basic facts of current events?</p>
<p>First we looked at how the political variables were distributed.</p>
<div id="political-affiliations-of-population" class="section level2">
<h2>Political Affiliations of Population</h2>
<p><img src="fake_news_project_files/figure-html/unnamed-chunk-3-1.png" width="1536" height="800" style="display: block; margin: auto;" /></p>
<p>Here we looked at political party and political ideology. A few of the responses were odd, with a couple very liberal republicans or very conservative democrats.</p>
</div>
<div id="pew-questions-vs-ideology" class="section level2">
<h2>Pew questions vs Ideology</h2>
<p><img src="fake_news_project_files/figure-html/unnamed-chunk-4-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre><code>## TableGrob (2 x 2) &quot;arrange&quot;: 4 grobs
##   z     cells    name           grob
## 1 1 (1-1,1-1) arrange gtable[layout]
## 2 2 (1-1,2-2) arrange gtable[layout]
## 3 3 (2-2,1-1) arrange gtable[layout]
## 4 4 (2-2,2-2) arrange gtable[layout]</code></pre>
<p>Then we looked at how the PEW questions distributed across ideology. We can see that answers for the PEW questions do sometimes differ among ideologies. Specifically people who are very liberal or very conservative have stronger beliefs about PEW6. Now we will try to create a model.</p>
<pre><code>## 
## Call:
## glm(formula = ideo ~ . - ideo, family = &quot;binomial&quot;, data = pew2)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.6465   0.3175   0.4355   0.5569   1.3968  
## 
## Coefficients:
##                              Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)                  1.292990   0.867112   1.491   0.1359  
## pew1Sometimes                0.048196   0.301476   0.160   0.8730  
## pew1Hardly ever              0.173217   0.448562   0.386   0.6994  
## pew1Never                   -0.255112   0.510397  -0.500   0.6172  
## pew2Sometimes                0.104120   0.291632   0.357   0.7211  
## pew2Hardly ever             -0.595031   0.365762  -1.627   0.1038  
## pew2Never                    0.142176   0.498423   0.285   0.7755  
## pew3No                       0.237207   0.321918   0.737   0.4612  
## pew4No                      -0.397574   0.374397  -1.062   0.2883  
## pew5aA fair amount           0.019028   0.264491   0.072   0.9426  
## pew5aNot much                0.485134   0.410179   1.183   0.2369  
## pew5aNone at all             0.436681   0.448035   0.975   0.3297  
## pew5bA fair amount           0.272191   0.311718   0.873   0.3826  
## pew5bNot much               -0.367039   0.331544  -1.107   0.2683  
## pew5bNone at all            -0.779750   0.366501  -2.128   0.0334 *
## pew5cA fair amount           0.226317   0.277051   0.817   0.4140  
## pew5cNot much                0.711334   0.431322   1.649   0.0991 .
## pew5cNone at all            -0.167619   0.381094  -0.440   0.6601  
## pew6Somewhat                 0.546774   0.246876   2.215   0.0268 *
## pew6Not very                 0.747650   0.488515   1.530   0.1259  
## pew6Not at all               0.935255   0.646614   1.446   0.1481  
## pew7Somewhat                 0.186220   0.278075   0.670   0.5031  
## pew7Not very                 0.618408   0.587877   1.052   0.2928  
## pew7Not at all              -0.410010   0.619065  -0.662   0.5078  
## sexFemale                    0.168168   0.227906   0.738   0.4606  
## age                          0.002660   0.005919   0.449   0.6531  
## educ2High school incomplete -1.128721   0.800929  -1.409   0.1588  
## educ2High school graduate    0.161097   0.697957   0.231   0.8175  
## educ2Some college           -0.085576   0.722163  -0.119   0.9057  
## educ2Associate degree        1.116957   0.816200   1.368   0.1712  
## educ2Bachelor degree         0.159826   0.704510   0.227   0.8205  
## educ2Some postgraduate      -0.202117   1.033290  -0.196   0.8449  
## educ2Postgraduate            0.202046   0.719334   0.281   0.7788  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 609.13  on 808  degrees of freedom
## Residual deviance: 564.53  on 776  degrees of freedom
## AIC: 630.53
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>After selecting all of the PEW questions and a couple of extra variables we created a logistic model. The dependent variable here is political ideology. We changed the variable from 5 levels to just 2, extreme and moderate. Extreme included people who were very liberal and very conservative. Moderate was everything else.</p>
<p><img src="fake_news_project_files/figure-html/unnamed-chunk-6-1.png" width="672" /> With a glm we need to find a cutoff point for what group a probability goes into. This plot lets us get a good idea. The cutoff should be around when the line starts to drop off. I’m choosing .79</p>
<p><img src="fake_news_project_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>This plot shows how accurate the predictions were. If a dot is above out cutoff line at .79, then it was predicted accurately. We see that ot got most of the moderates right but it looks like not much more than half of the extremes were correct. We can look at this accuracy mathematically.</p>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction Extreme Moderate
##   Extreme       33       71
##   Moderate      68      637
##                                           
##                Accuracy : 0.8282          
##                  95% CI : (0.8004, 0.8536)
##     No Information Rate : 0.8752          
##     P-Value [Acc &gt; NIR] : 1.0000          
##                                           
##                   Kappa : 0.2236          
##  Mcnemar&#39;s Test P-Value : 0.8653          
##                                           
##             Sensitivity : 0.32673         
##             Specificity : 0.89972         
##          Pos Pred Value : 0.31731         
##          Neg Pred Value : 0.90355         
##              Prevalence : 0.12485         
##          Detection Rate : 0.04079         
##    Detection Prevalence : 0.12855         
##       Balanced Accuracy : 0.61323         
##                                           
##        &#39;Positive&#39; Class : Extreme         
## </code></pre>
<p>Our model had a 82% accuracy rate. The specificity (true negative rate) is very high, but the sensitivity ( true positive rate) is very low. In this model a positive was extreme and a negative was moderate. This could be because of the low sample size of extreme ideologies. Next we made a model with political party being the dependent variable.</p>
<pre><code>## [1] &quot;Republican&quot;    &quot;Democrat&quot;      &quot;Independent&quot;   &quot;No preference&quot;
## [5] &quot;Other party&quot;</code></pre>
<p><img src="fake_news_project_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>This time our cutoff will be .49.</p>
<p><img src="fake_news_project_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>This time republican is a positive and democrat is a negative. Again, we should have a higher specificity than sensitivity.</p>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   Republican Democrat
##   Republican        101       61
##   Democrat          117      225
##                                           
##                Accuracy : 0.6468          
##                  95% CI : (0.6033, 0.6886)
##     No Information Rate : 0.5675          
##     P-Value [Acc &gt; NIR] : 0.0001701       
##                                           
##                   Kappa : 0.2579          
##  Mcnemar&#39;s Test P-Value : 3.749e-05       
##                                           
##             Sensitivity : 0.4633          
##             Specificity : 0.7867          
##          Pos Pred Value : 0.6235          
##          Neg Pred Value : 0.6579          
##              Prevalence : 0.4325          
##          Detection Rate : 0.2004          
##    Detection Prevalence : 0.3214          
##       Balanced Accuracy : 0.6250          
##                                           
##        &#39;Positive&#39; Class : Republican      
## </code></pre>
<p>This model had a higher sensitivity than the previous onebut it had a lower specificity. The overall accuracy was also lower.</p>
<p>Overall these models showed that accurate predictions should be possible with better data. I think with a higher sample size and more specific questions political ideology can be predicted with fake news opinions.</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
